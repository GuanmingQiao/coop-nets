---
title: ''
output:
  html_document: default
  html_notebook: default
---

# Import libraries

```{r, warning=F, message=F}
library(ggplot2)
library(lme4)
library(lmerTest)
library(tidyr)
library(dplyr)
library(qdap)
library(stringr)
library(knitr)
library(xtable)
library(readr)
setwd("C:/Users/wmonroe4/Local/research/pragmatics/coop-nets/behavioralAnalysis/")
```

# Pre-processing human data

First, we want to clean the data: join data frames together, remove games where participants were confused, spoke english as a second language, or didn't complete all trials.

Note: there's a bunch of additional pre-processing that it's still be nice to do. For instance, it would be nice to strip all the meta-commentary (e.g. "oops" after missing, complaining about task, etc.)

```{r}
msgs = read_csv("./humanOutput/colorReferenceMessage2.csv") %>%
  rename(msgTime = time, 
         role = sender)

clks = read.csv("./humanOutput/colorReferenceClicks2.csv") %>%
  mutate(condition = factor(condition, levels = c("closer", "further", "equal"), 
                            labels = c("close", "split", "far"))) %>%
  rename(clkTime = time)

subjInfo = read.csv("./humanOutput/colorReferenceSubjectInfo2.csv") %>%
  rename(gameid = gameID) %>%
  select(-workerid)

rawAggregated <- clks %>% 
  left_join(msgs, by = c("gameid", "roundNum")) %>%
  left_join(subjInfo, by = c("gameid", "role")) 

goodGames <- unique((rawAggregated %>% 
  filter(nativeEnglish == "yes") %>%
  filter(confused == "yes") %>%
  group_by(gameid) %>%
  filter(length(unique(roundNum)) == 50))$gameid)

combined_human <- clks %>%
  left_join(msgs, by = c("gameid", "roundNum")) %>%
  filter(gameid %in% goodGames) %>%
  mutate(numOutcome = ifelse(outcome == "true", 1, 0)) %>%
  mutate(numRawWords = wc(contents)) %>%
  filter(numRawWords > 0) %>% # Get rid of NAs from empty string messages
  mutate(strippedContents = str_replace_all(contents, "[^[:alnum:][:space:]']",' ')) %>%
  do(mutate(., cleanMsg = rm_stopwords(.$strippedContents, tm::stopwords("english"), 
                                       separate = F))) %>%
  mutate(numCleanChars = nchar(as.character(cleanMsg))) %>%
  mutate(numCleanWords = wc(cleanMsg)) %>%
  filter(numRawWords < mean(numRawWords) + 4*sd(numRawWords)) %>%
  mutate(source = 'human')
```

# Preprocessing model data

Template for pulling in listener & speaker

```{r}
makeModelDF <- function(listenerOutput, speakerOutput, sourceLabel) {
  robo_msgs = read.csv(speakerOutput) %>%
    rename(msgTime = time, role = sender) %>%
    mutate(role = "speaker") %>%
    mutate(contents = trimws(as.character(contents)))

  robo_clks = read.csv(listenerOutput) %>%
    mutate(condition = factor(condition, levels = c("closer", "further", "equal"), 
                              labels = c("close", "split", "far"))) %>%
    rename(clkTime = time)

  robo_rawAggregated <- robo_clks %>% 
    left_join(robo_msgs, by = c("gameid", "roundNum")) 

  combined_model <- robo_rawAggregated %>%
    mutate(numOutcome = ifelse(outcome == "true", 1, 0)) %>%
    mutate(numRawWords = 1 + str_count(contents, fixed(" "))) %>%
    mutate(strippedContents = str_replace_all(contents, "[^[:alnum:][:space:]']",' ')) %>%
    do(mutate(., cleanMsg = rm_stopwords(.$strippedContents, tm::stopwords("english"), 
                                         separate = F))) %>%
    mutate(numCleanChars = nchar(as.character(cleanMsg))) %>%
    mutate(numCleanWords = 1 + str_count(cleanMsg, fixed(" "))) %>%
    filter(numCleanWords < mean(numCleanWords) + 4*sd(numCleanWords)) %>%
    mutate(source = sourceLabel) 
}
```

Next, pull in S2/L2 model output

```{r}
literalModel <- makeModelDF(
  "./modelOutput/listener_big_l0_untuned_clickedObj.csv",
  "./modelOutput/speaker_big_s0_untuned_sampled_message.csv",
  "literal"
)
     
pragmaticModel <- makeModelDF(
  "./modelOutput/listener_big_l2_heldout_clickedObj.csv",
  "./modelOutput/speaker_big_sl_perp_sampled_message.csv",
  "pragmatic"
)
```


```{r}
combined = rbind(combined_human, literalModel, pragmaticModel) 
paste(c(length(unique(combined$gameid)), 
        "complete games w/ native english speakers out of a total of",
        length(unique(subjInfo$gameid))), collapse = " ")
```

# Listener analysis: Do people make more mistakes on harder trials?

```{r}
library(bootstrap)

## for bootstrapping 95% confidence intervals
## by Michael Frank: https://github.com/langcog/pragmods/blob/master/analysis/useful_dplyr.R
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
  mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}

listener_df = combined %>% 
  group_by(gameid, roundNum, source) %>% 
  filter(row_number()==1) %>% # limit to one row per round
  ungroup()

listenerSummary = listener_df %>% group_by(condition, source) %>%
  summarize(percentCorrect = mean(numOutcome), 
            low = ci.low(numOutcome),
            high = ci.high(numOutcome)) 
```

```{r}
pdf("../writing/2016/figures/changedByCondition.pdf", width=6,height=3,paper='special')
dodge <- position_dodge(width=0.9)
listener_df %>% 
  filter(source != 'human') %>%
  select(gameid, roundNum, source, numOutcome, condition) %>%
  spread(source, numOutcome) %>%
  filter(!is.na(literal) & !is.na(pragmatic)) %>% # NAs come from diff exclusions
  mutate(improvement = ifelse(!literal & pragmatic, 100, 0),
         decline = ifelse(literal & !pragmatic, 100, 0)) %>%
#         nochange = ifelse(literal == pragmatic, 1, 0)) %>%
  group_by(condition) %>%
  summarize("improvedMS" = mean(improvement), 
            "declinedMS" = mean(decline),
            # "se" = 50 * sqrt(1/length(improvement)),
            "improvedLS" = ci.low(improvement),
            "declinedLS" = ci.low(decline),
            "improvedHS" = ci.high(improvement),
            "declinedHS" = ci.high(decline)
            # "nochangeM" = mean(nochange)
            ) %>%
  gather(key, count, ends_with("S")) %>%
  mutate(key = gsub(".$", "", key)) %>%
  extract(key, c("change", "statistic"), "(.*)(.)") %>%
  spread(statistic, count) %>%
  ggplot(aes(x = condition, y = M, fill = change)) +
    geom_bar(stat = 'identity', position = dodge) +
    geom_errorbar(aes(ymax = M + H, ymin = M - L),
                  position=dodge, width=0.25) +
    theme_bw() +
    ylab("% of trials changed, L0 -> L*")
dev.off()
```


### Run mixed model:

```{r}
conditionMod = glmer(numOutcome ~ condition*source + (1 | gameid), family = "binomial", 
                     data = listener_df);
summary(conditionMod)
```

We find main effects of difficulty and of model; also interaction where humans are *much* better at "easy" condition while computers are only moderately better...

### Make human vs. model table

```{r}
listenerSummary %>%
  select(-low, -high) %>%
  spread(condition, percentCorrect)
```

### Make bar plot

```{r}
pdf("../writing/2016/figures/listenerAccuracy.pdf", width = 6, height = 3)

ordering <- function(source) {
  match(source, c("literal", "pragmatic", "human"))
}

dodge <- position_dodge(width=0.9)
listenerSummary %>%
  mutate(sourceNum = paste(ordering(source), source)) %>%
  ggplot(aes(x = condition, y = percentCorrect, fill = sourceNum)) +
    geom_bar(stat = "identity", position = "dodge") +
    geom_errorbar(aes(ymax = percentCorrect + high, ymin = percentCorrect - low), 
                  position=dodge, width=0.25) + 
    coord_cartesian(ylim = c(0.7, 1.0)) +
    ylab("% correct") +
    scale_fill_discrete("agent", labels=c("literal (L0)", "pragmatic (L1)", "human")) +
    theme_bw()
dev.off()
```

# Generate latex table for TACL paper:

Note that taggedColorMsgs.csv is created in tagPOS.ipynb.

We're going to run both human and model output through a pipeline to get a table with the different conditions as columns and different metrics as rows... 

```{r}
taggedDF = read_csv("taggedColorMsgs2.csv") %>% 
  rename(role = sender) %>% 
  mutate(source = ifelse(source == "model", "pragmatic", source)) %>%
  mutate(contents = trimws(as.character(contents)))

informativityDF = read_csv("informativities.csv") %>%
  rename(role = sender) %>% 
  mutate(source = ifelse(source == "model", "pragmatic", source)) %>%
  mutate(contents = trimws(as.character(contents)))

# TODO: present se in table (e.g. in parens after mean)
resultTable = combined %>% 
  filter(source %in% c("human", "pragmatic")) %>%
  left_join(taggedDF) %>%
  left_join(informativityDF) %>%
  filter(numCleanChars > 0) %>% # Get rid of NAs from empty strings
  mutate(comparativesIndicator = numComp > 0) %>%
  mutate(superlativesIndicator = numSuper > 0) %>%
  mutate(negativesIndicator = str_count(contents, fixed("not ")) > 0) %>%
  mutate(specificityIndicator = specificity > 7) %>%
   group_by(gameid, condition, source) %>%
   summarise(numWordsPerMessage = mean(numCleanWords),
             numCharsPerMessage = mean(numCleanChars),
             comparativesRate = mean(comparativesIndicator),
             superlativesRate = mean(superlativesIndicator),
             negativesRate = mean(negativesIndicator),
             specificityRate = sum(specificityIndicator, na.rm = T)) %>%
   group_by(condition, source) %>% 
   summarize("# WordsM" = mean(numWordsPerMessage), 
             "# CharsM" = mean(numCharsPerMessage),
             numWordsPerMessageSE = sd(numWordsPerMessage)/sqrt(length(numWordsPerMessage)),
             "% NegativesM" = mean(negativesRate),
             numNegativesSE = sd(negativesRate)/sqrt(length(negativesRate)),
             "% ComparativesM" = mean(comparativesRate),
             "% SuperlativesM" = mean(superlativesRate),
             "% High SpecificityM" = mean(specificityRate)) %>%
  gather(metric, mu, ends_with("M")) %>%
  #gather(garbage, se, ends_with("SE")) %>%
  mutate("metric (per message)" = gsub(".$", "", metric)) %>%
  select(-ends_with("SE"), -metric) %>%
  unite(comb, source,condition) %>%
  mutate(comb = ordered(comb, 
                        levels = c('human_far', 'human_split', 'human_close',
                                  'pragmatic_far', 'pragmatic_split', 'pragmatic_close'))) %>%
  spread(comb, mu)

topRow <- paste0(paste0('& \\multicolumn{3}{c}{', 
                        unique(combined$source), 
                        '}', collapse=''), '\\\\')
secondRow <- paste0('& ', 
                    paste0(rep(c("far", "split", "close"), 2), collapse='& '),
                    '\\\\')

addtorow <- list(
  pos = list(-1, 0), 
  command = c(topRow,secondRow)
)
print(xtable(resultTable, label = "table:metrics", align = "llrrr|rrr"), 
      add.to.row= addtorow, include.rownames = FALSE, include.colnames = F,
      floating.environment = "table*")
```

Statistically more or less of different things?

```{r}
specificityDF = combined %>% 
  filter(source %in% c("human")) %>%
  left_join(informativityDF) %>%
  mutate(specificityIndicator = specificity > 7)

summary(glmer(specificityIndicator ~ condition + (1 | gameid), 
             data = specificityDF,
             family = 'binomial',
             contrasts = list(condition =  contr.treatment(3, base=which(levels(specificityDF$condition) == 'far')))))

ggplot(specificityDF, aes(x = condition)) +
  geom_bar()
```
